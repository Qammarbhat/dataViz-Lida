{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3fc15ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55e30d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mongodb+srv://chinarquantum:GHboz7Yq0DX1yVtF@cqai.wvbbg.mongodb.net/?retryWrites=true&w=majority&appName=CQAI\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# os.environ.clear()\n",
    "load_dotenv()\n",
    "\n",
    "# MongoDB connection URI (change if needed)\n",
    "MONGO_URI = os.environ.get(\"MONGO_URI\")\n",
    "print(MONGO_URI)\n",
    "\n",
    "DB_NAME = \"ems\"\n",
    "ATTENDANCE_COLLECTION = \"attendances\"\n",
    "USER_COLLECTION = \"users\"\n",
    "OUTPUT_CSV = \"attendances_export.csv\"\n",
    "\n",
    "def export_merged_data_to_csv():\n",
    "    client = pymongo.MongoClient(MONGO_URI)\n",
    "    db = client[DB_NAME]\n",
    "\n",
    "    # Fetch documents\n",
    "    attendances = list(db[ATTENDANCE_COLLECTION].find())\n",
    "    users = list(db[USER_COLLECTION].find())\n",
    "\n",
    "    if not attendances or not users:\n",
    "        print(\"One or both collections are empty.\")\n",
    "        return\n",
    "\n",
    "    # Create DataFrames\n",
    "    attend_df = pd.DataFrame(attendances)\n",
    "    users_df = pd.DataFrame(users)\n",
    "\n",
    "    # Convert ObjectId to string for merging\n",
    "    attend_df['user'] = attend_df['user'].astype(str)\n",
    "    users_df['_id'] = users_df['_id'].astype(str)\n",
    "\n",
    "    # Select only necessary user fields\n",
    "    user_fields = ['_id', 'name', 'position', 'joiningDate', 'linkedInId', 'githubId', 'leaveDate', 'address']\n",
    "    users_df = users_df[user_fields]\n",
    "\n",
    "    # Merge: attendances.user -> users._id\n",
    "    merged_df = pd.merge(attend_df, users_df, left_on='user', right_on='_id', how='left')\n",
    "    # print(merged_df.head())\n",
    "    # Export to CSV\n",
    "    # merged_df.to_csv(OUTPUT_CSV, index=False)\n",
    "    print(f\"Exported merged data to '{OUTPUT_CSV}' with {len(merged_df)} records.\")\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87e19f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported merged data to 'attendances_export.csv' with 111 records.\n"
     ]
    }
   ],
   "source": [
    "merged_df = export_merged_data_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "112cd6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_id_x', 'user', 'date', 'checkIn', 'totalHours', 'status', 'breaks',\n",
       "       'createdAt', 'updatedAt', '__v', 'checkOut', 'overtimeHours',\n",
       "       'regularHours', 'overworkingMinutes', '_id_y', 'name', 'position',\n",
       "       'joiningDate', 'linkedInId', 'githubId', 'leaveDate', 'address'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b716611c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.drop([\"_id_x\", \"__v\", \"_id_y\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "332b265d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>date</th>\n",
       "      <th>checkIn</th>\n",
       "      <th>totalHours</th>\n",
       "      <th>status</th>\n",
       "      <th>breaks</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>updatedAt</th>\n",
       "      <th>checkOut</th>\n",
       "      <th>overtimeHours</th>\n",
       "      <th>regularHours</th>\n",
       "      <th>overworkingMinutes</th>\n",
       "      <th>name</th>\n",
       "      <th>position</th>\n",
       "      <th>joiningDate</th>\n",
       "      <th>linkedInId</th>\n",
       "      <th>githubId</th>\n",
       "      <th>leaveDate</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67175cb20d39c16d5f2af408</td>\n",
       "      <td>2025-01-08 03:58:13.257</td>\n",
       "      <td>{'time': 2025-01-08 03:58:13.260000, 'location...</td>\n",
       "      <td>14.03</td>\n",
       "      <td>present</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-01-08 03:58:13.272</td>\n",
       "      <td>2025-01-16 04:06:54.422</td>\n",
       "      <td>{'time': 2025-01-08 18:00:00, 'location': {'la...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67175cb20d39c16d5f2af408</td>\n",
       "      <td>2025-01-10 06:06:30.675</td>\n",
       "      <td>{'time': 2025-01-10 06:06:30.676000, 'location...</td>\n",
       "      <td>11.89</td>\n",
       "      <td>present</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-01-10 06:06:30.677</td>\n",
       "      <td>2025-01-16 04:06:55.074</td>\n",
       "      <td>{'time': 2025-01-10 18:00:00, 'location': {'la...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67175cb20d39c16d5f2af408</td>\n",
       "      <td>2025-01-13 07:23:17.888</td>\n",
       "      <td>{'time': 2025-01-13 07:23:17.889000, 'location...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>present</td>\n",
       "      <td>[{'startTime': 2025-01-13 07:24:27.239000, 'en...</td>\n",
       "      <td>2025-01-13 07:23:17.890</td>\n",
       "      <td>2025-01-13 07:25:02.079</td>\n",
       "      <td>{'time': 2025-01-13 07:25:02.077000, 'location...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6784c241e12fe0ae8dd55e46</td>\n",
       "      <td>2025-01-13 07:50:54.377</td>\n",
       "      <td>{'time': 2025-01-13 07:50:54.377000, 'location...</td>\n",
       "      <td>10.15</td>\n",
       "      <td>present</td>\n",
       "      <td>[{'startTime': 2025-01-13 07:51:27.071000, 'en...</td>\n",
       "      <td>2025-01-13 07:50:54.378</td>\n",
       "      <td>2025-01-16 04:06:55.965</td>\n",
       "      <td>{'time': 2025-01-13 18:00:00, 'location': {'la...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sahreen Haider</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>sahreen-haider</td>\n",
       "      <td>sahreen-haider</td>\n",
       "      <td>[]</td>\n",
       "      <td>Pulwama, Jammu and Kashmir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6784cdfce12fe0ae8dd56107</td>\n",
       "      <td>2025-01-14 06:16:21.661</td>\n",
       "      <td>{'time': 2025-01-14 06:16:21.662000, 'location...</td>\n",
       "      <td>11.73</td>\n",
       "      <td>present</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-01-14 06:16:21.663</td>\n",
       "      <td>2025-01-16 04:06:56.405</td>\n",
       "      <td>{'time': 2025-01-14 18:00:00, 'location': {'la...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Owais Bin Mushtaq</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>owais-bin-mushtaq-066a04211</td>\n",
       "      <td>HakimOwais</td>\n",
       "      <td>[{'startDate': '2025-01-15', 'leaveDate': '202...</td>\n",
       "      <td>Pulwama, J&amp;K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       user                    date  \\\n",
       "0  67175cb20d39c16d5f2af408 2025-01-08 03:58:13.257   \n",
       "1  67175cb20d39c16d5f2af408 2025-01-10 06:06:30.675   \n",
       "2  67175cb20d39c16d5f2af408 2025-01-13 07:23:17.888   \n",
       "3  6784c241e12fe0ae8dd55e46 2025-01-13 07:50:54.377   \n",
       "4  6784cdfce12fe0ae8dd56107 2025-01-14 06:16:21.661   \n",
       "\n",
       "                                             checkIn  totalHours   status  \\\n",
       "0  {'time': 2025-01-08 03:58:13.260000, 'location...       14.03  present   \n",
       "1  {'time': 2025-01-10 06:06:30.676000, 'location...       11.89  present   \n",
       "2  {'time': 2025-01-13 07:23:17.889000, 'location...        0.03  present   \n",
       "3  {'time': 2025-01-13 07:50:54.377000, 'location...       10.15  present   \n",
       "4  {'time': 2025-01-14 06:16:21.662000, 'location...       11.73  present   \n",
       "\n",
       "                                              breaks               createdAt  \\\n",
       "0                                                 [] 2025-01-08 03:58:13.272   \n",
       "1                                                 [] 2025-01-10 06:06:30.677   \n",
       "2  [{'startTime': 2025-01-13 07:24:27.239000, 'en... 2025-01-13 07:23:17.890   \n",
       "3  [{'startTime': 2025-01-13 07:51:27.071000, 'en... 2025-01-13 07:50:54.378   \n",
       "4                                                 [] 2025-01-14 06:16:21.663   \n",
       "\n",
       "                updatedAt                                           checkOut  \\\n",
       "0 2025-01-16 04:06:54.422  {'time': 2025-01-08 18:00:00, 'location': {'la...   \n",
       "1 2025-01-16 04:06:55.074  {'time': 2025-01-10 18:00:00, 'location': {'la...   \n",
       "2 2025-01-13 07:25:02.079  {'time': 2025-01-13 07:25:02.077000, 'location...   \n",
       "3 2025-01-16 04:06:55.965  {'time': 2025-01-13 18:00:00, 'location': {'la...   \n",
       "4 2025-01-16 04:06:56.405  {'time': 2025-01-14 18:00:00, 'location': {'la...   \n",
       "\n",
       "   overtimeHours  regularHours  overworkingMinutes               name  \\\n",
       "0            NaN           NaN                 NaN                NaN   \n",
       "1            NaN           NaN                 NaN                NaN   \n",
       "2            NaN           NaN                 NaN                NaN   \n",
       "3            NaN           NaN                 NaN     Sahreen Haider   \n",
       "4            NaN           NaN                 NaN  Owais Bin Mushtaq   \n",
       "\n",
       "                    position joiningDate                   linkedInId  \\\n",
       "0                        NaN         NaT                          NaN   \n",
       "1                        NaN         NaT                          NaN   \n",
       "2                        NaN         NaT                          NaN   \n",
       "3  Machine Learning Engineer  2024-03-01               sahreen-haider   \n",
       "4             Data Scientist  2023-11-01  owais-bin-mushtaq-066a04211   \n",
       "\n",
       "         githubId                                          leaveDate  \\\n",
       "0             NaN                                                NaN   \n",
       "1             NaN                                                NaN   \n",
       "2             NaN                                                NaN   \n",
       "3  sahreen-haider                                                 []   \n",
       "4      HakimOwais  [{'startDate': '2025-01-15', 'leaveDate': '202...   \n",
       "\n",
       "                      address  \n",
       "0                         NaN  \n",
       "1                         NaN  \n",
       "2                         NaN  \n",
       "3  Pulwama, Jammu and Kashmir  \n",
       "4                Pulwama, J&K  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72924d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(OUTPUT_CSV, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0196de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sample Document from 'attendances' Collection ---\n",
      "- _id: ObjectId\n",
      "- user: ObjectId\n",
      "- date: datetime\n",
      "- checkIn: dict\n",
      "  - time: datetime\n",
      "  - location: dict\n",
      "    - latitude: float\n",
      "    - longitude: float\n",
      "- totalHours: float\n",
      "- status: str\n",
      "- breaks: list (contains:\n",
      "    - Dictionary:\n",
      "    - startTime: datetime\n",
      "    - endTime: datetime\n",
      "    - duration: float\n",
      "    - _id: ObjectId\n",
      "- createdAt: datetime\n",
      "- updatedAt: datetime\n",
      "- __v: int\n",
      "- checkOut: dict\n",
      "  - time: datetime\n",
      "  - location: dict\n",
      "    - latitude: float\n",
      "    - longitude: float\n",
      "\n",
      "--- Sample Document from 'users' Collection ---\n",
      "- _id: ObjectId\n",
      "- email: str\n",
      "- password: str\n",
      "- joiningDate: datetime\n",
      "- position: str\n",
      "- name: str\n",
      "- aadhar: str\n",
      "- panNo: str\n",
      "- isSuperUser: bool\n",
      "- isApproved: str\n",
      "- invitedBy: ObjectId\n",
      "- image: str\n",
      "- address: str\n",
      "- linkedInId: str\n",
      "- phone: str\n",
      "- githubId: str\n",
      "- dateOfBirth: datetime\n",
      "- gender: str\n",
      "- leaveDate: list (contains:\n",
      "    - Dictionary:\n",
      "    - startDate: str\n",
      "    - leaveDate: str\n",
      "    - leave_status: str\n",
      "    - leaveDays: int\n",
      "    - reason: str\n",
      "    - description: str\n",
      "    - assignedAdmin: ObjectId\n",
      "    - _id: ObjectId\n",
      "- __v: int\n",
      "- approvalDate: datetime\n",
      "- tags: list (contains:\n",
      "    - str)\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# os.environ.clear()\n",
    "load_dotenv()\n",
    "\n",
    "# MongoDB connection URI (change if needed)\n",
    "MONGO_URI = os.environ.get(\"MONGO_URI\")\n",
    "DATABASE_NAME = \"ems\"  # Replace with your database name\n",
    "\n",
    "try:\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    db = client[DATABASE_NAME]\n",
    "    attendances_collection = db[\"attendances\"]\n",
    "    users_collection = db[\"users\"]\n",
    "\n",
    "    # Fetch one document from each collection\n",
    "    sample_attendance = attendances_collection.find_one()\n",
    "    sample_user = users_collection.find_one()\n",
    "\n",
    "    print(\"--- Sample Document from 'attendances' Collection ---\")\n",
    "    if sample_attendance:\n",
    "        def print_structure(document, indent=0):\n",
    "            for key, value in document.items():\n",
    "                print(\"  \" * indent + f\"- {key}: {type(value).__name__}\", end=\"\")\n",
    "                if isinstance(value, dict):\n",
    "                    print()\n",
    "                    print_structure(value, indent + 1)\n",
    "                elif isinstance(value, list):\n",
    "                    print(\" (contains:\")\n",
    "                    if value:\n",
    "                        if isinstance(value[0], dict):\n",
    "                            print(\"  \" * (indent + 1) + \"  - Dictionary:\")\n",
    "                            print_structure(value[0], indent + 2)\n",
    "                        else:\n",
    "                            print(\"  \" * (indent + 1) + f\"  - {type(value[0]).__name__})\")\n",
    "                    else:\n",
    "                        print(\")\")\n",
    "                else:\n",
    "                    print()\n",
    "        print_structure(sample_attendance)\n",
    "    else:\n",
    "        print(\"No documents found in the 'attendances' collection.\")\n",
    "\n",
    "    print(\"\\n--- Sample Document from 'users' Collection ---\")\n",
    "    if sample_user:\n",
    "        print_structure(sample_user)\n",
    "    else:\n",
    "        print(\"No documents found in the 'users' collection.\")\n",
    "\n",
    "except ConnectionError as e:\n",
    "    print(f\"Could not connect to MongoDB: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "finally:\n",
    "    if 'client' in locals():\n",
    "        client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8450b253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'employee_dataset.csv' created successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# os.environ.clear()\n",
    "load_dotenv()\n",
    "\n",
    "# MongoDB connection URI (change if needed)\n",
    "MONGO_URI = os.environ.get(\"MONGO_URI\")\n",
    "DATABASE_NAME = \"ems\"  # Replace with your database name\n",
    "\n",
    "try:\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    db = client[DATABASE_NAME]\n",
    "    attendances_collection = db[\"attendances\"]\n",
    "    users_collection = db[\"users\"]\n",
    "\n",
    "    # Fetch all users\n",
    "    users_data = list(users_collection.find())\n",
    "\n",
    "    # Prepare a list to store employee data for the CSV\n",
    "    employee_data = []\n",
    "\n",
    "    for user in users_data:\n",
    "        user_id = str(user['_id'])\n",
    "        attendances = list(attendances_collection.find({\"user\": user['_id']}))\n",
    "\n",
    "        total_working_hours = 0\n",
    "        check_in_check_out_count = 0\n",
    "        working_days = set()\n",
    "        leave_dates_list = []\n",
    "        total_breaks = 0\n",
    "        total_break_duration = 0\n",
    "        break_start_end_times = []\n",
    "\n",
    "        if attendances:\n",
    "            check_in_check_out_count = len(attendances)\n",
    "            for attendance in attendances:\n",
    "                if attendance.get('totalHours'):\n",
    "                    total_working_hours += attendance['totalHours']\n",
    "                if attendance.get('checkIn') and attendance.get('checkOut'):\n",
    "                    working_days.add(attendance['date'].strftime('%Y-%m-%d'))\n",
    "                if attendance.get('breaks'):\n",
    "                    total_breaks += len(attendance['breaks'])\n",
    "                    for break_entry in attendance['breaks']:\n",
    "                        if break_entry.get('duration'):\n",
    "                            total_break_duration += break_entry['duration']\n",
    "                        if break_entry.get('startTime') and break_entry.get('endTime'):\n",
    "                            break_start_end_times.append(\n",
    "                                f\"{break_entry['startTime'].strftime('%Y-%m-%d %H:%M:%S')} - {break_entry['endTime'].strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "                            )\n",
    "\n",
    "        leave_count = len(user.get('leaveDate', []))\n",
    "        leave_dates_raw = user.get('leaveDate', [])\n",
    "        for leave in leave_dates_raw:\n",
    "            leave_dates_list.append(f\"{leave.get('startDate', 'N/A')} to {leave.get('leaveDate', 'N/A')}\")\n",
    "\n",
    "        employee_info = {\n",
    "            \"Employee ID\": user_id,\n",
    "            \"Employee Name\": user.get('name', 'N/A'),\n",
    "            \"Employee Joining Date\": user.get('joiningDate', None).strftime('%Y-%m-%d') if user.get('joiningDate') else 'N/A',\n",
    "            \"Employee Gender\": user.get('gender', 'N/A'),\n",
    "            \"Employee Leave Count\": leave_count,\n",
    "            \"Total Working Hours Recorded\": total_working_hours,\n",
    "            \"Total Check-in Check-out Records\": check_in_check_out_count,\n",
    "            \"Working Days Count\": len(working_days),\n",
    "            \"Employee Status\": user.get('isApproved', 'N/A'),\n",
    "            \"Leave Dates\": \", \".join(leave_dates_list) if leave_dates_list else 'N/A',\n",
    "            \"Total Break Count\": total_breaks,\n",
    "            \"Total Break Duration (Hours)\": total_break_duration,\n",
    "            \"Break Start - End Times\": \"; \".join(break_start_end_times) if break_start_end_times else 'N/A',\n",
    "            \"Leave Details\": \", \".join([f\"From {leave.get('startDate', 'N/A')} to {leave.get('leaveDate', 'N/A')}\" for leave in leave_dates_raw]) if leave_dates_raw else 'N/A'\n",
    "        }\n",
    "        employee_data.append(employee_info)\n",
    "\n",
    "    # Create a Pandas DataFrame\n",
    "    df = pd.DataFrame(employee_data)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    csv_file_path = \"employee_dataset.csv\"\n",
    "    df.to_csv(csv_file_path, index=False, encoding='utf-8')\n",
    "\n",
    "    print(f\"CSV file '{csv_file_path}' created successfully.\")\n",
    "\n",
    "except ConnectionError as e:\n",
    "    print(f\"Could not connect to MongoDB: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "finally:\n",
    "    if 'client' in locals():\n",
    "        client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac214c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: 'NoneType' object has no attribute 'strftime'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# os.environ.clear()\n",
    "load_dotenv()\n",
    "\n",
    "# MongoDB connection URI (change if needed)\n",
    "MONGO_URI = os.environ.get(\"MONGO_URI\")\n",
    "DATABASE_NAME = \"ems\"  # Replace with your database name\n",
    "\n",
    "try:\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    db = client[DATABASE_NAME]\n",
    "    attendances_collection = db[\"attendances\"]\n",
    "    users_collection = db[\"users\"]\n",
    "\n",
    "    # Fetch all attendance records\n",
    "    attendances_data = list(attendances_collection.find())\n",
    "\n",
    "    # Prepare a list to store attendance data for the CSV\n",
    "    attendance_data = []\n",
    "\n",
    "    for attendance in attendances_data:\n",
    "        user_id = attendance['user']\n",
    "        user = users_collection.find_one({\"_id\": user_id})  # Find the user for this attendance record\n",
    "\n",
    "        if user:\n",
    "            user_name = user.get('name', 'N/A')\n",
    "            user_joining_date = user.get('joiningDate', None).strftime('%Y-%m-%d') if user and user.get('joiningDate') else 'N/A'\n",
    "            user_gender = user.get('gender', 'N/A')\n",
    "            leave_count = len(user.get('leaveDate', []))\n",
    "            leave_dates_raw = user.get('leaveDate', [])\n",
    "            leave_dates_list = [f\"From {leave.get('startDate', 'N/A')} to {leave.get('leaveDate', 'N/A')}\" for leave in leave_dates_raw] if leave_dates_raw else ['N/A']\n",
    "            employee_status = user.get('isApproved', 'N/A')\n",
    "        else:\n",
    "            user_name = 'N/A'\n",
    "            user_joining_date = 'N/A'\n",
    "            user_gender = 'N/A'\n",
    "            leave_count = 0\n",
    "            leave_dates_list = ['N/A']\n",
    "            employee_status = 'N/A'\n",
    "\n",
    "        check_in_check_out_count = 1  # Each attendance record represents one check-in/check-out\n",
    "        working_days = {attendance['date'].strftime('%Y-%m-%d')}  # Use a set to store unique dates\n",
    "        total_breaks = len(attendance.get('breaks', []))\n",
    "        total_break_duration = sum(b.get('duration', 0) for b in attendance.get('breaks', []))\n",
    "        break_start_end_times = [\n",
    "            f\"{b.get('startTime', datetime(1970,1,1)).strftime('%Y-%m-%d %H:%M:%S')} - {b.get('endTime', datetime(1970,1,1)).strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "            for b in attendance.get('breaks', [])\n",
    "        ]\n",
    "\n",
    "        attendance_info = {\n",
    "            \"Employee ID\": str(user_id),\n",
    "            \"Employee Name\": user_name,\n",
    "            \"Employee Joining Date\": user_joining_date,\n",
    "            \"Employee Gender\": user_gender,\n",
    "            \"Employee Leave Count\": leave_count,\n",
    "            \"Total Working Hours Recorded\": attendance.get('totalHours', 0),\n",
    "            \"Total Check-in Check-out Records\": check_in_check_out_count,\n",
    "            \"Working Days Count\": len(working_days),\n",
    "            \"Employee Status\": employee_status,\n",
    "            \"Leave Dates\": \", \".join(leave_dates_list),\n",
    "            \"Total Break Count\": total_breaks,\n",
    "            \"Total Break Duration (Hours)\": total_break_duration,\n",
    "            \"Break Start - End Times\": \"; \".join(break_start_end_times) if break_start_end_times else 'N/A',\n",
    "            \"Leave Details\": \", \".join(leave_dates_list)\n",
    "        }\n",
    "        attendance_data.append(attendance_info)\n",
    "\n",
    "    # Create a Pandas DataFrame\n",
    "    df = pd.DataFrame(attendance_data)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    csv_file_path = \"attendance_dataset.csv\"\n",
    "    df.to_csv(csv_file_path, index=False, encoding='utf-8')\n",
    "\n",
    "    print(f\"CSV file '{csv_file_path}' created successfully.\")\n",
    "\n",
    "except ConnectionError as e:\n",
    "    print(f\"Could not connect to MongoDB: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "finally:\n",
    "    if 'client' in locals():\n",
    "        client.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b41b1d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'attendance_dataset.csv' created successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# os.environ.clear()\n",
    "load_dotenv()\n",
    "\n",
    "# MongoDB connection URI (change if needed)\n",
    "MONGO_URI = os.environ.get(\"MONGO_URI\")\n",
    "DATABASE_NAME = \"ems\"  # Replace with your database name\n",
    "\n",
    "try:\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    db = client[DATABASE_NAME]\n",
    "    attendances_collection = db[\"attendances\"]\n",
    "    users_collection = db[\"users\"]\n",
    "\n",
    "    # Fetch all attendance records\n",
    "    attendances_data = list(attendances_collection.find())\n",
    "\n",
    "    # Prepare a list to store attendance data for the CSV\n",
    "    attendance_data = []\n",
    "\n",
    "    for attendance in attendances_data:\n",
    "        user_id = attendance['user']\n",
    "        user = users_collection.find_one({\"_id\": user_id})  # Find the user for this attendance record\n",
    "\n",
    "        if user:\n",
    "            user_name = user.get('name', 'N/A')\n",
    "            user_joining_date = user.get('joiningDate', None)\n",
    "            user_joining_date_str = user_joining_date.strftime('%Y-%m-%d') if isinstance(user_joining_date, datetime) else 'N/A'\n",
    "            user_gender = user.get('gender', 'N/A')\n",
    "            leave_count = len(user.get('leaveDate', []))\n",
    "            leave_dates_raw = user.get('leaveDate', [])\n",
    "            leave_dates_list = [f\"From {leave.get('startDate', 'N/A')} to {leave.get('leaveDate', 'N/A')}\" for leave in leave_dates_raw] if leave_dates_raw else ['N/A']\n",
    "            employee_status = user.get('isApproved', 'N/A')\n",
    "        else:\n",
    "            user_name = 'N/A'\n",
    "            user_joining_date_str = 'N/A'\n",
    "            user_gender = 'N/A'\n",
    "            leave_count = 0\n",
    "            leave_dates_list = ['N/A']\n",
    "            employee_status = 'N/A'\n",
    "\n",
    "        check_in_check_out_count = 1  # Each attendance record represents one check-in/check-out\n",
    "        working_days = {attendance['date'].strftime('%Y-%m-%d')}  # Use a set to store unique dates\n",
    "        total_breaks = len(attendance.get('breaks', []))\n",
    "        total_break_duration = sum(b.get('duration', 0) for b in attendance.get('breaks', []))\n",
    "        break_start_end_times = []\n",
    "        for b in attendance.get('breaks', []):\n",
    "            start_time = b.get('startTime')\n",
    "            end_time = b.get('endTime')\n",
    "            start_time_str = start_time.strftime('%Y-%m-%d %H:%M:%S') if isinstance(start_time, datetime) else 'N/A'\n",
    "            end_time_str = end_time.strftime('%Y-%m-%d %H:%M:%S') if isinstance(end_time, datetime) else 'N/A'\n",
    "            break_start_end_times.append(f\"{start_time_str} - {end_time_str}\")\n",
    "\n",
    "        attendance_info = {\n",
    "            \"Employee ID\": str(user_id),\n",
    "            \"Employee Name\": user_name,\n",
    "            \"Employee Joining Date\": user_joining_date_str,\n",
    "            \"Employee Gender\": user_gender,\n",
    "            \"Employee Leave Count\": leave_count,\n",
    "            \"Total Working Hours Recorded\": attendance.get('totalHours', 0),\n",
    "            \"Total Check-in Check-out Records\": check_in_check_out_count,\n",
    "            \"Working Days Count\": len(working_days),\n",
    "            \"Employee Status\": employee_status,\n",
    "            \"Leave Dates\": \", \".join(leave_dates_list),\n",
    "            \"Total Break Count\": total_breaks,\n",
    "            \"Total Break Duration (Hours)\": total_break_duration,\n",
    "            \"Break Start - End Times\": \"; \".join(break_start_end_times) if break_start_end_times else 'N/A',\n",
    "            \"Leave Details\": \", \".join(leave_dates_list)\n",
    "        }\n",
    "        attendance_data.append(attendance_info)\n",
    "\n",
    "    # Create a Pandas DataFrame\n",
    "    df = pd.DataFrame(attendance_data)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    csv_file_path = \"attendance_dataset.csv\"\n",
    "    df.to_csv(csv_file_path, index=False, encoding='utf-8')\n",
    "\n",
    "    print(f\"CSV file '{csv_file_path}' created successfully.\")\n",
    "\n",
    "except ConnectionError as e:\n",
    "    print(f\"Could not connect to MongoDB: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "finally:\n",
    "    if 'client' in locals():\n",
    "        client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed94f48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib==3.10.0\n",
      "  Using cached matplotlib-3.10.0-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Using cached matplotlib-3.10.0-cp310-cp310-win_amd64.whl (8.0 MB)\n",
      "Installing collected packages: matplotlib\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\admin\\.conda\\envs\\lida-demo\\lib\\site-packages)\n",
      "error: uninstall-no-record-file\n",
      "\n",
      "× Cannot uninstall matplotlib 3.10.0\n",
      "╰─> The package's contents are unknown: no RECORD file was found for matplotlib.\n",
      "\n",
      "hint: You might be able to recover from this via: pip install --force-reinstall --no-deps matplotlib==3.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --force-reinstall --no-deps matplotlib==3.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8607767f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib.backends.registry'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbase64\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdisplay_charts_from_json\u001b[39m(json_path: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput.json\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      8\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m    Loads and displays base64-encoded charts from a JSON file.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03m        json_path (str): Path to the JSON file containing chart data.\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\admin\\.conda\\envs\\lida-demo\\lib\\site-packages\\matplotlib\\__init__.py:161\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m parse_version\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[1;32m--> 161\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrcsetup\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cycler  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\admin\\.conda\\envs\\lida-demo\\lib\\site-packages\\matplotlib\\rcsetup.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BackendFilter, backend_registry\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ls_mapper\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Colormap, is_color_like\n",
      "File \u001b[1;32mc:\\Users\\admin\\.conda\\envs\\lida-demo\\lib\\site-packages\\matplotlib\\backends\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BackendFilter, backend_registry  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# NOTE: plt.switch_backend() (called at import time) will add a \"backend\"\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# attribute here for backcompat.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m _QT_FORCE_QT5_BINDING \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib.backends.registry'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_charts_from_json(json_path: str = \"output.json\"):\n",
    "    \"\"\"\n",
    "    Loads and displays base64-encoded charts from a JSON file.\n",
    "\n",
    "    Args:\n",
    "        json_path (str): Path to the JSON file containing chart data.\n",
    "    \"\"\"\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for i, item in enumerate(data):\n",
    "        goal = item[\"goal\"]\n",
    "        base64_str = item[\"chart_base64\"]\n",
    "        img_bytes = base64.b64decode(base64_str)\n",
    "        image = Image.open(BytesIO(img_bytes))\n",
    "\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Goal {i+1}: {goal}\", fontsize=12)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aedf06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lida-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
